{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Due: Sun Oct. 21 @ 9pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we'll perform a hypothesis test and clean some data before training a regression model.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the comments below and fill in the blanks (____) to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# To suppress FutureWarnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hypothesis Testing with an A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we work at a large company that is developing online data science tools. Currently the tool has interface type A but we'd like to know if using interface tool B might be more efficient.\n",
    "To measure this, we'll look at length of active work on a project (aka project length).\n",
    "We'll perform an A/B test where half of the projects will use interface A and half will use interface B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in project lengths from '../data/project_lengths'\n",
    "# there should be 1000 observations for both interfaces\n",
    "df_project = pd.read_csv('../data/project_lengths.csv')\n",
    "df_project.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference in mean project length between interface A and B\n",
    "# for consistency, subtracting A from B\n",
    "# hint: this number should be negative here (could interpret as faster)\n",
    "mean_A = ____\n",
    "mean_B = ____\n",
    "observed_mean_diff = ____\n",
    "observed_mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll perform a permutation test to see how significant this result is\n",
    "# generate 10000 random permutation samples of mean difference\n",
    "# hint: use np.random.permutation\n",
    "rand_mean_diffs = []\n",
    "n_samples = 10000\n",
    "combined_times = np.concatenate([df_project.lengths_A.values, df_project.lengths_B.values])\n",
    "n_A = ____ # number of observations for page A\n",
    "for i in range(n_samples):\n",
    "    rand_perm = ____\n",
    "    rand_mean_A = ____\n",
    "    rand_mean_B = ____\n",
    "    rand_mean_diffs.append(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn to plot the distribution of mean differences\n",
    "# use plt.vlines to plot a line at our observed difference in means (ymin=0,ymax=0.5)\n",
    "_ = ____\n",
    "_ = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot should seem to indicate significance, but let's calculate a one-tailed p_value using rand_mean_diffs\n",
    "p_value = ____\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate the effect size of our observation\n",
    "# this is the absolute value of the observed_mean_diff divided by the standard deviation of the combined_times\n",
    "observed_effect_size = ____\n",
    "observed_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this for the next 2 steps\n",
    "from statsmodels.stats.power import tt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the power of our current experiment?\n",
    "# e.g. how likely is it that correctly decided that B is better than A \n",
    "#   given the observed effect size, number of observations and alpha level we used above\n",
    "# since these are independent samples we can use tt_ind_solve_power\n",
    "# hint: the power we get should not be good\n",
    "power = tt_ind_solve_power(effect_size = observed_effect_size,  # what we just calculated\n",
    "                           nobs1 = n_A,         # the number of observations in A\n",
    "                           alpha = 0.05,        # our alpha level\n",
    "                           power = ____,        # what we're interested in\n",
    "                           ratio = 1            # the ratio of number of observations of A and B\n",
    "                          )\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many observations for each of A and B would we need to get a power of .9\n",
    "#   for our observed effect size and alpha level\n",
    "# eg. having a 90% change of correctly deciding B is better than A\n",
    "n_obs_A = ____\n",
    "n_obs_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is provided by World Bank Open Data https://data.worldbank.org/, processed as in Homework 1.\n",
    "\n",
    "We will be performing regression with respect to GDP and classification with respect to Income Group.\n",
    "To do that we will first need to do a little more data prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df_country = pd.read_csv('../data/country_electricity_by_region.csv')\n",
    "\n",
    "# rename columns for ease of reference\n",
    "columns = ['country_code','short_name','region','income_group','access_to_electricity','gdp','population_density',\n",
    "           'population_total','unemployment','region_europe','region_latin_america_and_caribbean',\n",
    "           'region_middle_east_and_north_africa','region_north_america','region_south_asia',\n",
    "           'region_subsaharan_africa']\n",
    "\n",
    "df_country.columns = columns\n",
    "df_country.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dummy variable 'gdp_missing' to indicate where 'gdp' is null\n",
    "df_country['gdp_missing'] = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groupby to find the number of missing gpd by income_level\n",
    "# write a lambda function to apply to the grouped data, counting the number of nulls per group\n",
    "df_country.groupby('income_group').gdp.apply(lambda x: ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing gdp values according to income_group mean\n",
    "# to do this, group by income_group \n",
    "# then apply a lambda function to the gdp column that uses the fillna function, filling with the mean\n",
    "# inplace is not available here, so assign back into the gdp column\n",
    "df_country.gdp = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that there are no longer any missing values in gdp\n",
    "assert ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'populiation_density_missing' dummy variable\n",
    "df_country['population_density_missing'] = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing population_density with median, grouping by region\n",
    "df_country.population_density = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a normalized 'gdp_zscore' column\n",
    "from ____ import ____\n",
    "df_country['gdp_zscore'] = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn to create a distplot (with rugplot indicators) and a boxplot of gdp_zscores to visualize outliers\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "_ = ____\n",
    "_ = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 10 country_code and gdp_zscore sorted by gdp_zscore\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a zscore cutoff to remove the top 4 outliers\n",
    "gdp_zscore_cutoff = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a normalized 'population_density_zscore' column\n",
    "df_country['population_density_zscore'] = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 10 country_code and population_density_zscore sorted by population_density_zscore\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a zscore cutoff to remove the top 5 outliers\n",
    "population_density_zscore_cutoff = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers (considering both gdp_zscore and population_density_zscore)\n",
    "df_country = df_country[(____) & (____)]\n",
    "df_country.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set of X with features (population_density, access_to_electricity) \n",
    "# and labels y (gdp)\n",
    "X = ____\n",
    "y = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and initialize a LinearRegression model using default parameters\n",
    "from ____ import ____\n",
    "lr = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the regressor on X and y\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the learned intercept and coefficients\n",
    "print(____)\n",
    "print(____)\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use this mask to easily index into our dataset\n",
    "country_mask = (df_country.country_code == 'CAN').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how far off is our model's prediction for Canada's gdp (country_code CAN) from it's actual gdp?\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new training set X that, in addition to population_density and access_to_electricity,\n",
    "# also includes the region_* dummies\n",
    "X = df_country[['population_density','access_to_electricity','region_europe','region_latin_america_and_caribbean',\n",
    "           'region_middle_east_and_north_africa','region_north_america','region_south_asia',\n",
    "           'region_subsaharan_africa']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new model and train, with fit_intercept=False\n",
    "lr = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did the prediction for CAN improve?\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coms007",
   "language": "python",
   "name": "coms007"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
